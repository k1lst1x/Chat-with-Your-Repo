import os
import re
import requests
import zipfile
import json
import requests
from django.shortcuts import render
from django.http import JsonResponse
from django.utils import timezone
from django.conf import settings
from django.contrib.auth.decorators import login_required
from .models import Chat
import g4f
from django.utils.html import escape
from django.utils.safestring import mark_safe
import markdown
from langchain_community.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_core.documents import Document
import shutil

from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_ASSISTANT_ID = os.getenv("OPENAI_ASSISTANT_ID")

CHROMA_DB_DIR = os.path.join(settings.BASE_DIR, "chroma_db")

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

def index_repository_for_rag(repo_path, repo_name, user_id):
    documents = []
    for root, _, files in os.walk(repo_path):
        for filename in files:
            if filename.endswith(('.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rb', '.php', '.html', '.css')):
                file_path = os.path.join(root, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    rel_path = os.path.relpath(file_path, repo_path)
                    doc = Document(
                        page_content=content,
                        metadata={
                            "file_path": rel_path,
                            "repo_name": repo_name,
                            "user_id": str(user_id)
                        }
                    )
                    documents.append(doc)
                except Exception:
                    continue

    if not documents:
        return

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = splitter.split_documents(documents)

    vectorstore_path = os.path.join(CHROMA_DB_DIR, f"{user_id}_{repo_name}")
    if os.path.exists(vectorstore_path):
        shutil.rmtree(vectorstore_path)

    db = Chroma.from_documents(
        documents=docs,
        embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),
        persist_directory=vectorstore_path
    )
    db.persist()


# def ask_openai(message):
#     response = g4f.ChatCompletion.create(
#         model="gpt-4",
#         messages=[
#             {
#                 "role": "system",
#                 "content": "Your task is to analyze a GitHub repository in great detail. "
#                            "Provide insights on the programming language used, frameworks, libraries, "
#                            "key functions, and any other relevant information about the repository. "
#                            "Offer a structured and detailed breakdown."
#             },
#             {"role": "user", "content": message},
#         ]
#     )
#     return response  # g4f —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É

# def ask_openai(message):
#     response = client.chat.completions.create(
#         model="gpt-4o-mini",
#         messages=[
#             {
#                 "role": "system",
#                 "content": "Your task is to analyze a GitHub repository in great detail. "
#                            "Provide insights on the programming language used, frameworks, libraries, "
#                            "key functions, and any other relevant information about the repository. "
#                            "Offer a structured and detailed breakdown."
#             },
#             {"role": "user", "content": message}
#         ]
#     )
#     return response.choices[0].message.content

# from g4f import ChatCompletion  # ‚ùå
from openai import OpenAI
from django.core.cache import cache  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è thread_id

client = OpenAI(api_key=OPENAI_API_KEY)

def ask_openai(message, user_id="default"):
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Redis/Django cache, —á—Ç–æ–±—ã —Ö—Ä–∞–Ω–∏—Ç—å —Ç—Ä–µ–¥ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    thread_key = f"openai_thread_{user_id}"
    thread_id = cache.get(thread_key)

    if not thread_id:
        thread = client.beta.threads.create()
        thread_id = thread.id
        cache.set(thread_key, thread_id, timeout=None)

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=message
    )

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞–Ω
    run = client.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=OPENAI_ASSISTANT_ID
    )

    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run
    import time
    while True:
        run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
        if run_status.status == "completed":
            break
        elif run_status.status in ["failed", "cancelled"]:
            return "‚ùå –û—à–∏–±–∫–∞: –ó–∞–ø—Ä–æ—Å –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å."
        time.sleep(1)

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
    messages = client.beta.threads.messages.list(thread_id=thread_id)
    last_message = messages.data[0].content[0].text.value
    return last_message

def get_default_branch(owner, repo):
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –≤–µ—Ç–∫—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."""
    api_url = f"https://api.github.com/repos/{owner}/{repo}"
    response = requests.get(api_url)
    if response.status_code == 200:
        return response.json().get("default_branch", "main")
    return "main"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é main, –µ—Å–ª–∏ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ

def download_github_repo(github_url):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π GitHub –≤ —Ñ–æ—Ä–º–∞—Ç–µ ZIP –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –≤ MEDIA_ROOT"""

    # –ò–∑–≤–ª–µ–∫–∞–µ–º owner –∏ repo –∏–∑ —Å—Å—ã–ª–∫–∏
    match = re.search(r"github\.com/([^/]+)/([^/]+)", github_url)
    if not match:
        return None, "Invalid GitHub URL"

    owner, repo = match.groups()
    
    default_branch = get_default_branch(owner, repo)
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ ZIP-–∞—Ä—Ö–∏–≤ –∏–∑ GitHub
    download_url = f"https://github.com/{owner}/{repo}/archive/refs/heads/{default_branch}.zip"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞–ø–∫–∞ MEDIA_ROOT, –µ—Å–ª–∏ –Ω–µ—Ç - —Å–æ–∑–¥–∞—ë–º
    if not os.path.exists(settings.MEDIA_ROOT):
        os.makedirs(settings.MEDIA_ROOT)

    media_path = os.path.join(settings.MEDIA_ROOT, f"{repo}.zip")

    response = requests.get(download_url, stream=True)
    if response.status_code != 200:
        return None, "Failed to download repository. Check if the repository exists and is public."

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ZIP-–∞—Ä—Ö–∏–≤
    with open(media_path, 'wb') as file:
        for chunk in response.iter_content(chunk_size=8192):
            file.write(chunk)

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
    extract_path = os.path.join(settings.MEDIA_ROOT, repo)
    if not os.path.exists(extract_path):
        os.makedirs(extract_path)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª ZIP-–∞—Ä—Ö–∏–≤–æ–º
    try:
        with zipfile.ZipFile(media_path, 'r') as zip_ref:
            zip_ref.extractall(extract_path)
    except zipfile.BadZipFile:
        return None, "Downloaded file is not a valid ZIP archive."

    return extract_path, None

LANGUAGE_EXTENSIONS = {
    'Python': ['.py'],
    'JavaScript': ['.js', '.jsx'],
    'TypeScript': ['.ts', '.tsx'],
    'Java': ['.java'],
    'C++': ['.cpp', '.hpp', '.h', '.cc'],
    'C': ['.c', '.h'],
    'Go': ['.go'],
    'PHP': ['.php'],
    'Ruby': ['.rb'],
    'Shell': ['.sh'],
}

def detect_language(file_path):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é —Ñ–∞–π–ª–∞."""
    _, ext = os.path.splitext(file_path)
    for language, extensions in LANGUAGE_EXTENSIONS.items():
        if ext in extensions:
            return language
    return "Unknown"

def extract_code_metadata(file_path):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã, –∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
            content = file.readlines()
    except Exception as e:
        return {'error': str(e)}

    imports = []
    classes = []
    functions = []

    for line in content:
        line = line.strip()

        # –ü–æ–∏—Å–∫ –∏–º–ø–æ—Ä—Ç–æ–≤
        if re.match(r'^\s*(import|from)\s+[\w.]+', line):
            imports.append(line)

        # –ü–æ–∏—Å–∫ –∫–ª–∞—Å—Å–æ–≤
        if re.match(r'^\s*class\s+\w+', line):
            classes.append(line)

        # –ü–æ–∏—Å–∫ —Ñ—É–Ω–∫—Ü–∏–π
        if re.match(r'^\s*def\s+\w+', line) or re.match(r'^\s*function\s+\w+', line):
            functions.append(line)

    return {
        'imports': imports,
        'classes': classes,
        'functions': functions
    }

def analyze_repository(repo_path, depth=0):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏, —É—á–∏—Ç—ã–≤–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏."""
    analysis = {'directories': {}, 'files': {}}

    for root, dirs, files in os.walk(repo_path):
        relative_path = os.path.relpath(root, repo_path)

        # –°–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
        analysis['directories'][relative_path] = dirs

        for file in files:
            file_path = os.path.join(root, file)
            language = detect_language(file_path)
            if language == "Unknown":
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –∫–æ–¥–æ–º

            file_analysis = extract_code_metadata(file_path)

            analysis['files'][file_path] = {
                'relative_path': relative_path,
                'language': language,
                'imports': file_analysis.get('imports', []),
                'classes': file_analysis.get('classes', []),
                'functions': file_analysis.get('functions', []),
            }

    return analysis

def summarize_repository(repo_analysis):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ OpenAI."""
    summary = ["üìå –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:\n"]

    for file, details in repo_analysis['files'].items():
        summary.append(f"üìÑ {file}\n"
                       f"üìå –Ø–∑—ã–∫: {details['language']}\n"
                       f"üì• –ò–º–ø–æ—Ä—Ç—ã: {len(details['imports'])}\n"
                       f"üì¶ –ö–ª–∞—Å—Å—ã: {len(details['classes'])}\n"
                       f"üîß –§—É–Ω–∫—Ü–∏–∏: {len(details['functions'])}\n")

    return "\n".join(summary)

def query_repository(question, repo_name, user_id):
    vectorstore_path = os.path.join(CHROMA_DB_DIR, f"{user_id}_{repo_name}")
    if not os.path.exists(vectorstore_path):
        return "‚ùå –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –µ–≥–æ."

    db = Chroma(
        persist_directory=vectorstore_path,
        embedding_function=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    )

    relevant_docs = db.similarity_search(question, k=10)
    context = "\n\n".join([doc.page_content[:1000] for doc in relevant_docs])
    print(context)

    prompt = (
        f"–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –∫–æ–¥. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n\n{context}\n\n"
        f"–í–æ–ø—Ä–æ—Å: {question}"
    )

    return ask_openai(prompt, user_id=user_id)


def analyze_and_ask_openai(repo_path, user_id):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ GPT."""
    repo_analysis = analyze_repository(repo_path)  # –õ–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    summary_text = summarize_repository(repo_analysis)  # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ OpenAI
    key_files_content = []
    for file_path, details in repo_analysis['files'].items():
        if "main" in file_path.lower() or "settings" in file_path.lower() or "config" in file_path.lower():
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    file_content = f.read()
                    key_files_content.append(f"üìÇ {file_path}\n```{file_content[:2000]}```\n")
            except Exception:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å
    index_repository_for_rag(repo_path, os.path.basename(repo_path), user_id=user_id)

    openai_prompt = (
        "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∫–æ–¥–∞. –î–∞–π –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞:\n\n"
        + summary_text +
        "\n\n–í–æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤:\n" +
        "\n".join(key_files_content)
    )

    openai_response = ask_openai(openai_prompt, user_id="analyzer")

    # return f"{summary_text}\n\nüí° OpenAI –∞–Ω–∞–ª–∏–∑:\n{openai_response}"
    return f"üí°–ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:\n{openai_response}"

from datetime import date
from django.db.models import Count

@login_required
def chatbot(request):
    user = request.user
    chats = Chat.objects.filter(user=user)

    if request.method == 'POST':
        message = request.POST.get('message')

        # üîí –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –ø–æ–¥–ø–∏—Å–∫—É
        # if not user.is_subscribed:
        #     from payments.models import Payment
        #     from payments.views import get_payment_link
        #     last_payment = Payment.objects.filter(user=user, status="UNPAID").last()
        #     if last_payment:
        #         payment_url = f"https://stage-checkout.ioka.kz/orders/{last_payment.ioka_order_id}"
        #     else:
        #         response = get_payment_link(request)
        #         payment_url = json.loads(response.content.decode("utf-8")).get("url")
        #     return JsonResponse({
        #         'message': message,
        #         'response': f'–£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–∏. –û–ø–ª–∞—Ç–∏—Ç–µ –µ—ë –ø–æ —Å—Å—ã–ª–∫–µ: <a href="{payment_url}" target="_blank">–û–ø–ª–∞—Ç–∏—Ç—å</a>'
        #     })

        if not message:
            return JsonResponse({'error': 'Message cannot be empty'}, status=400)

        # üìä –õ–∏–º–∏—Ç 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å
        today = date.today()
        daily_count = Chat.objects.filter(user=user, created_at__date=today).count()
        if daily_count >= 1000:
            response_text = (
                'üõë –í—ã –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –≤ 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è. '
                '–ü–æ–¥–æ–∂–¥–∏—Ç–µ –¥–æ –∑–∞–≤—Ç—Ä–∞ –∏–ª–∏ –æ—Ñ–æ—Ä–º–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É –¥–ª—è –±–µ–∑–ª–∏–º–∏—Ç–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.'
            )
            return JsonResponse({'message': message, 'response': response_text})

        # üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ GitHub —Å—Å—ã–ª–∫–∏ –∏–ª–∏ –æ–±—ã—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        github_link = re.search(r"https?://github\.com/[^\s]+", message)
        if github_link:
            repo_path, error = download_github_repo(github_link.group(0))
            if error:
                return JsonResponse({'message': message, 'response': f"–û—à–∏–±–∫–∞: {error}"})
            response_text = analyze_and_ask_openai(repo_path, user_id=user.id)
        if message.lower().startswith("–≤–æ–ø—Ä–æ—Å –ø–æ —Ä–µ–ø–æ:"):
            parts = message.split(":", 2)
            if len(parts) == 3:
                repo_name = parts[1].strip()
                question = parts[2].strip()
                response_text = query_repository(question, repo_name, user.id)
            else:
                response_text = "‚ö†Ô∏è –§–æ—Ä–º–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å: '–í–æ–ø—Ä–æ—Å –ø–æ —Ä–µ–ø–æ: repo_name: –≤–∞—à –≤–æ–ø—Ä–æ—Å'"
        else:
            response_text = ask_openai(message, user_id=user.id)

        # üîπ –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown ‚Üí HTML
        response_text = markdown.markdown(
            response_text,
            extensions=['fenced_code', 'tables', 'nl2br', 'extra'],
            output_format="html5"
        )

        # üí¨ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        chat = Chat.objects.create(
            user=user, message=message, response=response_text, created_at=timezone.now()
        )

        return JsonResponse({'message': message, 'response': response_text})

    return render(request, 'home.html', {'chats': chats, 'github_token': GITHUB_TOKEN})

def index(request):
    return render(request, 'index.html')